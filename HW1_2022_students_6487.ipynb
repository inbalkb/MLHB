{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<div>Machine Learning and Human Behavior - 236608 - Winter 2022-2023</div>\n",
        "<h1>Homework #1 - Binary Choice üêæ</h1>\n",
        "</center>\n"
      ],
      "metadata": {
        "id": "I2dnZs04GXRK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Instructions and submission guidelines\n",
        "The goal of this homework is to introduce you to google colab notebooks and simple binary choice models, and implement evaluation methods which will be used in the first workshop next week.\n",
        "\n",
        "* Clone this notebook and complete the exercise:\n",
        "    * Aim for clear and concise solutions.\n",
        "    * Indicate clearly with a text block the sections of your solutions.\n",
        "    * Answer dry questions in text (markdown) blocks and wet questions in code blocks.\n",
        "* Submission guidelines:\n",
        "    * Add a text block in the beginning of your notebook with your IDs.\n",
        "    * When you're done, restart the notebook and make sure that everything runs smoothly (Runtime->\"Restart and Run All\")\n",
        "    * Export your notebook as ipynb (File->Download->\"Download .ipynb\")\n",
        "    * Submit through the course website. Remember to list partner IDs when you submit.\n",
        "* **Due date**: Monday 14/11/2022, 23:59\n",
        "* For any questions regarding this homework task, contact [Eden](mailto:edens@campus.technion.ac.il).\n"
      ],
      "metadata": {
        "id": "zfGIerIGVPnl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "BzVK8Q3KVLRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "xQeKqB9mFBP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task #1: numpy + pandas syntax warm-up\n",
        "\n",
        "Goal of this task is to make sure you are familiar with basic numpy and pandas syntax. \n"
      ],
      "metadata": {
        "id": "tWnY9bjCNO34"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## numpy\n",
        "\n",
        "Consider the following functions:\n",
        "\n",
        "\\begin{align}\n",
        "f(x)\n",
        "&=\\begin{cases}\n",
        "x & x \\ge 0 \\\\\n",
        "0 & x < 0\n",
        "\\end{cases}\\\\\n",
        "g(x)\n",
        "&=\\begin{cases}\n",
        "\\sqrt{x} & x \\ge 0 \\\\\n",
        "-2(-x)^{\\frac{1}{3}} & x < 0\n",
        "\\end{cases}\n",
        "\\end{align}\n",
        "\n",
        "Implement $f(x)$, $g(x)$. Use numpy vectorized numpy calculations, and avoid using loops.\n",
        "\n",
        "The functions should accept a numpy array `x` as an argument.\n",
        "\n",
        "üîµ **Answer**:"
      ],
      "metadata": {
        "id": "f_hW0qA2PnNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x):\n",
        "    ## YOUR SOLUTION\n",
        "\n",
        "def g(x):\n",
        "    ## YOUR SOLUTION"
      ],
      "metadata": {
        "id": "F38cB1VUN2dU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot $f(x)$ for $x\\in[-1,1]$. Add a title for the plot, x/y labels, and a legend.\n",
        "\n",
        "üîµ **Answer**:"
      ],
      "metadata": {
        "id": "v5hwPj4uOrgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.linspace(-1,1,200)\n",
        "y1 = f(x)\n",
        "y2 = g(x)\n",
        "\n",
        "fig,ax = plt.subplots()\n",
        "\n",
        "## YOUR SOLUTION"
      ],
      "metadata": {
        "id": "HTogccsaO72l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pandas"
      ],
      "metadata": {
        "id": "vQjakW_CRgC-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get ourselves familiar with the syntax, we use the classic [iris](https://archive.ics.uci.edu/ml/datasets/iris) dataset:"
      ],
      "metadata": {
        "id": "d-o34AQNSOb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris_df = load_iris(as_frame=True)['data']\n",
        "iris_df.head()"
      ],
      "metadata": {
        "id": "E8jQwUWQReve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How many rows in `iris_df` have `sepal_length>=6`? \n",
        "Use vectorized calculations, and avoid using loops.\n",
        "\n",
        "üîµ **Answer**:"
      ],
      "metadata": {
        "id": "4nb1UeJVSJ6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR SOLUTION"
      ],
      "metadata": {
        "id": "IlpU3UZaRpyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot a histogram of `sepal_width` with 20 bins:\n",
        "\n",
        "üîµ **Answer**:"
      ],
      "metadata": {
        "id": "pD8Ko_amTU4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR SOLUTION"
      ],
      "metadata": {
        "id": "aq8EWPrcTdIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task \\#2: Simple choice prediction\n"
      ],
      "metadata": {
        "id": "sZpLOZz3tzv9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this task is to get you familiar with the object structure we will use in the workshops."
      ],
      "metadata": {
        "id": "3hCPJiyWT7Cm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Abstract population models \n",
        "\n",
        "For the implementation of behavioral models, we define the abstract classes which handle data generation and formatting. As we will mostly use these classes through their public interface, there is no need to go through the implementation in detail."
      ],
      "metadata": {
        "id": "wYFiyO1Kvf_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DiscreteChoiceEnvironment:\n",
        "    \"\"\"\n",
        "    Generic class for discrete-choice dataset generation\n",
        "    \"\"\"\n",
        "    n_features = 8\n",
        "    observations_per_user = 10\n",
        "    train_user_proportion = 0.6\n",
        "\n",
        "    def _generate_user_attributes(self, n_users):\n",
        "        \"\"\"\n",
        "        Generate latent parameters for users.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_users : int\n",
        "\n",
        "        Output\n",
        "        ------\n",
        "        users : ndarray of shape (n_users, n_features)\n",
        "        \"\"\"\n",
        "        return np.random.normal(\n",
        "            loc=1,\n",
        "            scale=0.1,\n",
        "            size=(\n",
        "                n_users,\n",
        "                self.n_features,\n",
        "            ),\n",
        "        )\n",
        "    \n",
        "    def _generate_item_attributes(self, n_users):\n",
        "        \"\"\"\n",
        "        Generate latent parameters for items.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_users : int\n",
        "\n",
        "        Output\n",
        "        ------\n",
        "        items : ndarray of shape\n",
        "                (n_users, observations_per_user, n_features)\n",
        "        \"\"\"\n",
        "        return np.random.normal(\n",
        "            size=(\n",
        "                n_users,\n",
        "                self.observations_per_user,\n",
        "                self.n_features,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "    def _choice(self, users, items):\n",
        "        \"\"\"\n",
        "        Discrete choice function\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        users : ndarray of shape (n_users, n_features)\n",
        "        items : ndarray of shape\n",
        "                (n_users, observations_per_user, n_features)\n",
        "\n",
        "        Output\n",
        "        ------\n",
        "        choice : Dict[str -> ndarray of shape(n_users, observations_per_user)]\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "    \n",
        "    def _generate_choice_dataset(self, n_users):\n",
        "        \"\"\"\n",
        "        Generate choice dataset, formatted as pandas dataframe.\n",
        "        \"\"\"\n",
        "        users = self._generate_user_attributes(n_users)\n",
        "        items = self._generate_item_attributes(n_users)\n",
        "        choice_dct = self._choice(users, items)\n",
        "        rows = []\n",
        "        for i in range(n_users):\n",
        "            for j in range(self.observations_per_user):\n",
        "                dct = {}\n",
        "                dct['user_id'] = f'{i}'\n",
        "                for k in range(self.n_features):\n",
        "                        dct[f'x_{k}'] = items[i,j,k]\n",
        "                for choice_type, choice_matrix in choice_dct.items():\n",
        "                    dct[choice_type] = choice_matrix[i,j]\n",
        "                rows.append(dct)\n",
        "        df = pd.DataFrame(rows)\n",
        "        return df\n",
        "    \n",
        "    def generate_train_eval_datasets(self, n_users):\n",
        "        n_train_users = int(n_users*self.train_user_proportion)\n",
        "        n_test_users = n_users - n_train_users\n",
        "        return (\n",
        "            self._generate_choice_dataset(n_train_users),\n",
        "            self._generate_choice_dataset(n_test_users),\n",
        "        )\n",
        "\n",
        "    def get_feature_columns(self):\n",
        "        return [\n",
        "            f'x_{k}'\n",
        "            for k in range(self.n_features)\n",
        "        ]\n",
        "\n",
        "\n",
        "class InnerProductTrueValueEnvironment(DiscreteChoiceEnvironment):\n",
        "    @staticmethod\n",
        "    def _true_value(users, items):\n",
        "        # true_value is an inner product u@x.\n",
        "        # Calculate using np.einsum, where:\n",
        "        # * i: user index\n",
        "        # * j: observation (item) index\n",
        "        # * k: feature\n",
        "        true_value = np.einsum('ik,ijk->ij', users, items)\n",
        "        return true_value"
      ],
      "metadata": {
        "id": "zcdxnhnaFBP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "We assume that decisions are made according to a latent inner product utility model. \n",
        "\n",
        "Specifically, we assume that each user $u$ is represented by a vector $u\\in U \\subseteq \\mathbb{R}^d$, and each item $x$ is represented by a vector $x\\in X \\subseteq \\mathbb{R}^d$. We assume that the true utility experienced by user $u$ from consuming item $x$ is defined as the inner product $v_u(x)=u^Tx$.\n",
        "\n",
        "The `InnerProductTrueValueEnvironment` class provides a simple interface which will be useful for simulation. Here we inherit from it to implement a behvarioal model which simulates rational choice:"
      ],
      "metadata": {
        "id": "KrG8O1lCDPXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RationalBinaryChoiceEnvironment(InnerProductTrueValueEnvironment):\n",
        "    \"\"\"\n",
        "    Dataset generator for binary choice with decision noise\n",
        "    \"\"\"\n",
        "    def _choice(self, users, items):\n",
        "        \"\"\"\n",
        "        Simulate discrete choice. User choose i\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        users : ndarray of shape (n_users, n_features)\n",
        "        items : ndarray of shape\n",
        "                (n_users, observations_per_user, n_features)\n",
        "\n",
        "        Output\n",
        "        ------\n",
        "        choice : Dict[str -> ndarray of shape(n_users, observations_per_user)]\n",
        "        \"\"\"\n",
        "        # Calculate the innner product to get the true value u.T@v. \n",
        "        # Result is a numpy array of shape (n_users, items_per_user)\n",
        "        true_value = self._true_value(users, items)\n",
        "        return {\n",
        "            'true_value': true_value,\n",
        "            'choice': true_value >= 0,\n",
        "        }"
      ],
      "metadata": {
        "id": "mYw1oJnDGwwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "As an example, here we instantiate an environment, and generate training and evaluation datasets with 1000 users. Note that the datasets are pandas DataFrames:"
      ],
      "metadata": {
        "id": "RYxGnvDZfF8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = RationalBinaryChoiceEnvironment()\n",
        "example_train_df, example_eval_df = env.generate_train_eval_datasets(n_users=1000)\n",
        "example_train_df.head()"
      ],
      "metadata": {
        "id": "eWlkyaRCSglw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the DataFrame above: The column `user_id` represents the user id, the columns `x_0`,...,`x_7` represent item features, the column `true_value` represents $v_u(x)$, and the column `choice` represent the actual choice (`choice==True` if $v_u(x)\\ge 0$)."
      ],
      "metadata": {
        "id": "YkB9I6o3SrzD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Welfare\n",
        "\n",
        "The *Welfare* associated with a predictor $f:X\\to\\{0,1\\}$ and evaluation set $S\\subseteq U \\times X$ is defined according to the following formula:\n",
        "$$\n",
        "\\mathrm{welfare}(f, S)=\\frac{1}{|S|}\\sum_{ (u,x) \\in S } f(x) v_u(x)\n",
        "$$\n",
        "where $f(x)\\in\\{0,1\\}$ is the model prediction, and $v_u(x)$ is the true valuation of the item, as defined in the introduction above.\n",
        "\n",
        "Implement the welfare function. \n",
        "\n",
        "The function should receive as input a prediction function `f` (e.g. `sklearn.linear_model.LogisticRegression.fit(...).predict`), an evaluation dataset (e.g as the evaluation set returned by `env.generate_train_eval_datasets(...)`), the name of the feature columns (e.g from `env.get_feature_columns()`), and the name of the column representing $v_u(x)$.\n",
        "\n",
        "üîµ **Answer**:"
      ],
      "metadata": {
        "id": "eShMgIp-vobE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def welfare(f, eval_df, feature_columns, value_column):\n",
        "    \"\"\"\n",
        "    Calculate the welfare for the given evaluation set\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    f : prediction function from pandas dataframe to {0,1}\n",
        "    eval_df : pandas DataFrame, as returned by env.generate_train_eval_datasets\n",
        "    feature_columns : names of feature columns (e.g `env.get_feature_columns()`)\n",
        "    value_column : name of value column (e.g `true_value`)\n",
        "\n",
        "    Output\n",
        "    ------\n",
        "    choice : Dict[str -> ndarray of shape(n_users, observations_per_user)]\n",
        "    \"\"\"\n",
        "    ## YOUR SOLUTION"
      ],
      "metadata": {
        "id": "pAbgKwW2xOkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simulation exercise\n",
        "\n",
        "In this exercise, we will examine the change in classification accuracy as a function of dataset size.\n",
        "\n",
        "For each dataset size in `n_users_vec` ($\\{3,6,\\dots,48\\}$):\n",
        "* Generate training/evaluation datasets with the given amount of users (`n_users`). \n",
        "* Use the training set to train two models: A Logistic Regression and a Random Forest. Both models should use the `choice` column as a binary label for training. \n",
        "  (Hint: Given a training dataframe `train_df`  generated by environment `env`, the command `train_df[env.get_feature_columns()]` returns a dataframe with features as columns).\n",
        "* Evaluate the accuracy of each model in predicting choice of the evaluation set.\n",
        "\n",
        "\n",
        "To reduce randomization noise, repeat the experiment 10 times for each dataset size, and average the results.\n",
        "\n",
        "üîµ **Answer**:"
      ],
      "metadata": {
        "id": "inqLvZ9mjZf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.linear_model\n",
        "import sklearn.ensemble\n",
        "\n",
        "n_repetitions = 10\n",
        "n_users_vec = np.arange(3,50,5)\n",
        "models = {\n",
        "    'logistic_regression': sklearn.linear_model.LogisticRegression,\n",
        "    'random_forest': sklearn.ensemble.RandomForestClassifier,\n",
        "}\n",
        "\n",
        "## YOUR SOLUTION"
      ],
      "metadata": {
        "id": "84eNV906iTFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explain the results. What do you see in the graphs? Why do you think the graphs look like this? \n",
        "\n",
        "üîµ **Answer**:\n",
        "\n",
        "(YOUR SOLUTION)\n",
        "\n"
      ],
      "metadata": {
        "id": "h749EAK6zJ9Y"
      }
    }
  ]
}